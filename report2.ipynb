{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgoZds3QODKrc0GdMwAO4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyukei/AI/blob/master/report2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#第2回 レポート課題 (12/20 23:55 締切)\n"
      ],
      "metadata": {
        "id": "HZGa3WnQXCL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題1\n",
        "### トピック9のnotebook1で示したRNNを用いたIMDBデータのP/N判定のコードを参考に、複数のネットワーク構造を設定して性能の違いを調べよ。また、調べたネットワーク構造の中から比較的性能が高くて学習時間が短いものをひとつ選び、学習データが極端に少ない状況からすべての学習データを用いる状況まで、段階的にデータを増やして学習データの量と識別器の性能の関係を調べよ。 "
      ],
      "metadata": {
        "id": "f41mz-9HXF51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備"
      ],
      "metadata": {
        "id": "8bk7dkUG4fKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ディープニューラルネットワークでの識別を Keras でコーディングします。Google ColabでGPUを使用するときは、「ランタイム」->「ランタイムのタイプを変更」-> ハードウェアアクセラレータ -> GPU を選ぶ。"
      ],
      "metadata": {
        "id": "fonjR0Xvdg94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime, os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "LFomrfzJdBHd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "jlSv7YW2drJS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセットについて"
      ],
      "metadata": {
        "id": "1b38lRd14Vrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMDBデータは映画のレビューに対して、P/N(肯定/否定)のラベルが付いた学習データである。\n",
        "\n",
        "ここでは、頻度上位10000語を対象とし、データの大きさは先頭の50単語に限定する。"
      ],
      "metadata": {
        "id": "4PdVFWy_c5W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "maxlen = 50\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=max_features)\n",
        "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y69q-ePEdcaY",
        "outputId": "1c9f915c-3b8d-41d7-a322-8e6777f2c5a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2071,   56,   26, ...,   19,  178,   32],\n",
              "       [8255,    5,    2, ...,   16,  145,   95],\n",
              "       [ 215,   28,  610, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   4,   65,  496, ...,    4, 3586,    2],\n",
              "       [  13,   18,   31, ...,   12,    9,   23],\n",
              "       [7585,    8, 2197, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データは単語ではなく、数字が入っている。これは、次のword_indexのindexに相当し、単語はword_indexのvalueに相当する。"
      ],
      "metadata": {
        "id": "Is0f6AR1eXlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()"
      ],
      "metadata": {
        "id": "M20-AkZYeHox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95792663-6893-4d7c-f60c-0e9ba72c9dbd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "単語インデックスを単語に戻して、元のデータにデコードする"
      ],
      "metadata": {
        "id": "2fj4JAMnelFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in X_train[0]])\n",
        "decoded_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "A41gQ7dqd_VZ",
        "outputId": "f8bfca2a-090b-4bcd-8a96-752bd796fa37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
        "```\n",
        "は「子供は素晴らしく、絶賛されるべきだ」というポジティブなレビューであった。\n",
        "\n",
        "出力は0か1である。0がネガティブで1がポジティブな映画のレビューとなっている。"
      ],
      "metadata": {
        "id": "2OUP-RMh3_vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40Odu04J2Wqv",
        "outputId": "1ffb0115-7230-4511-941d-921cf56f907c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "出力は１でポジティブとなっている。\n",
        "\n",
        "確かにレビューとネガポジ判定は一致していて、データセットはうまく機能していると分かる。\n"
      ],
      "metadata": {
        "id": "INrckYrY26FD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimpleRNNを構成して学習させる。"
      ],
      "metadata": {
        "id": "1xtrHfQves4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNとはRecursive Neural Network(再帰型ニューラルネットワーク)の略である。\n",
        "\n",
        "Recursiveとあるように中間層で演算結果を再帰的に自身に出力する\n",
        "\n",
        "具体的には、一時刻前の中間層の出力を次の入力と結合して中間層に入力する。\n",
        "\n",
        "そのため、前の単語が次の単語に影響をあたえる自然言語処理に適していると言われる。\n",
        "\n",
        "RNNの学習方法は３ステップである\n",
        "\n",
        "1. ネットワークの構造の決定\n",
        "1. fix関数を用いて学習実行\n",
        "1. テストデータを用いて評価"
      ],
      "metadata": {
        "id": "Qlsz2tOlXSEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ネットワークの構造"
      ],
      "metadata": {
        "id": "9XqI9zMZ7xK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "layers.Embedding(max_features, 128)\n",
        "```\n",
        "入力の単語インデックスをone-hotベクトル（インデックスに対応する次元の値が1、それ以外の次元の値は0）とみなしたものを低次元のベクトルに変換するEmbedding（埋め込み）層\n",
        "```\n",
        "layers.SimpleRNN(64)\n",
        "```\n",
        " Embeddin層の出力とひとつ前の自身の出力を結合したものに対して重み付き和を求めて活性化関数を適用するSimpleRNN層\n",
        " ```\n",
        "layers.Dense(1, activation='sigmoid')\n",
        " ```\n",
        " SimpleRNN層の出力の重み付き和を求めて活性化関数を適用し、出力を求めるDense層からなる。KerasではSequentialクラスのインスタンスに対してaddメソッドでこれらの層を積み重ねて識別のためのニューラルネットを構成する。"
      ],
      "metadata": {
        "id": "9AU5RooQZmWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = keras.Sequential([\n",
        "    layers.Embedding(max_features, 128),#埋め込み層\n",
        "    layers.SimpleRNN(64),#outputの次元\n",
        "    layers.Dense(1, activation='sigmoid')#全結合層\n",
        "]) \n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR56oJ_weClN",
        "outputId": "6bc80f8a-c598-4b4f-bc5f-ba4ba72dd168"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                12352     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,292,417\n",
            "Trainable params: 1,292,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習\n",
        "作成したネットワークのcompileメソッドで最適化器・損失関数・評価基準を指定した後、fitメソッドに学習データと学習時のパラメータを与えて学習する。"
      ],
      "metadata": {
        "id": "LPyyoC4baPaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習を行う。fit関数を用いる。\n",
        "主な引数は以下である。 \n",
        "```\n",
        "fit(X_train, y_train, epochs=5, batch_size=32,validation_split=0.2)\n",
        "X_train => 訓練データ\n",
        "y_train => 教師ラベル\n",
        "epochs => エポック数\n",
        "batch_size => バッチサイズ\n",
        "validation_split => X_trainをさらに分割し、訓練データと検証用に分ける割合\n",
        "```\n",
        "\n",
        "fitメソッドの引数validation_splitを指定すると、指定された割合を検証用データとして学習データから分割できる。\n",
        "\n",
        "1epoch毎に検証用データの判定性能を表示させることができる。\n",
        "\n",
        "ちなみに、エポック数とは学習回数を表す。\n",
        "エポック数が少ないと、パラメータが適切に収束する前に学習が終了する。また、あまりにも学習をしすぎると特定のデータのみに強い「過学習」を起こしてしまう。また、学習にも時間がかかる。\n",
        "\n",
        "バッチサイズは学習データを分割してグループ化(バッチ)したときのデータ数を示す。\n",
        "バッチサイズが大きいと、局所的解を避けることができ、学習時間を短くすることができる一方で、入力データが平均化され、データの個々の特徴が失われる。一方サイズが小さいと、個々の特徴が反映されるが、時間がかかり、局所解のトラップにかかる可能性が高い。\n"
      ],
      "metadata": {
        "id": "c8F8Q2-QaXf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])#訓練プロセス(最適化方、損失関数)\n",
        "model1.fit(X_train, y_train, epochs=5, batch_size=32,validation_split=0.2)#訓練開始(epochs でエポック,バッチサイズを決める)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UvpBN_heIc9",
        "outputId": "1d81ca25-7b4b-4936-99ec-b76ef3ae3447"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 25s 36ms/step - loss: 0.5554 - acc: 0.6949 - val_loss: 0.4695 - val_acc: 0.7738\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.3272 - acc: 0.8623 - val_loss: 0.5247 - val_acc: 0.7454\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 23s 37ms/step - loss: 0.1482 - acc: 0.9463 - val_loss: 0.6566 - val_acc: 0.7416\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 22s 34ms/step - loss: 0.0564 - acc: 0.9814 - val_loss: 0.8510 - val_acc: 0.7654\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 0.9386 - val_acc: 0.7518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15ebd02820>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 評価\n",
        "テストデータを用いて評価を行う。\n",
        "１に近いほど正答率が高い"
      ],
      "metadata": {
        "id": "5yc7v-lRaxdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model1.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvqqp4UGeMCI",
        "outputId": "99e80943-f42b-4edf-c247-2ea49743d9a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 6ms/step - loss: 0.9539 - acc: 0.7501\n",
            "Test accuracy: 0.7501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 双方向LSTM\n",
        "LSTMはLong Short Term Memory(長・短期記憶)の略である\n",
        "\n",
        "RNNの勾配消失問題を解消するために考えられたネットワークシステムである。\n",
        "RNNはデータ数が多いと勾配消失し重みを更新ができなくなる。\n",
        "\n",
        "RNNが情報をそのまま渡すがLSTMでは中間層を用いて次に渡す。\n",
        "\n",
        "SimpleRNNでは```layers.SimpleRNN(64)```としていたとろを``` layers.Bidirectional(layers.LSTM(64))```に変更する。引数64はoutputの層の数を示す。\n",
        "\n",
        "SimpleRNNと同様に、ネットワークの構造決定、学習、評価を行う"
      ],
      "metadata": {
        "id": "tggcFW2HmS_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential([\n",
        "    layers.Embedding(max_features, 128),\n",
        "    layers.Bidirectional(layers.LSTM(64)),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU4HVeBXeOa5",
        "outputId": "afbfa9e4-b205-45a1-cfb3-6a1f64f34138"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model2.fit(X_train, y_train, epochs=5, batch_size=32,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpfGzZQheRMg",
        "outputId": "8f98bfec-3abd-4b62-a5d9-a00e4504de56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 8s 10ms/step - loss: 0.2017 - acc: 0.9224 - val_loss: 0.5042 - val_acc: 0.7916\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1105 - acc: 0.9611 - val_loss: 0.6703 - val_acc: 0.7852\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.0561 - acc: 0.9814 - val_loss: 0.8881 - val_acc: 0.7776\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.0276 - acc: 0.9918 - val_loss: 1.0400 - val_acc: 0.7694\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.0237 - acc: 0.9923 - val_loss: 1.0861 - val_acc: 0.7730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1645bc5910>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model2.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZDqjR-beUxi",
        "outputId": "e7c9ae50-28f8-4835-e7a9-440349c319c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 4ms/step - loss: 1.0576 - acc: 0.7821\n",
            "Test accuracy: 0.7821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ll-qCKR1pWRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題2\n",
        "### トピック9のnotebook2のコードを参考に、事前学習モデルを用いる設定で、学習データが極端に少ない状況からすべての学習データを用いる状況まで、段階的にデータを増やして学習データの量と識別器の性能の関係を調べよ。"
      ],
      "metadata": {
        "id": "_C8zhwFlXMWJ"
      }
    }
  ]
}